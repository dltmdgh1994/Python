{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import os,glob\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curve(history):\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['loss'], 'b-', label='loss')\n",
    "    plt.plot(history.history['val_loss'], 'r--', label='val_loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['accuracy'], 'g-', label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], 'k--', label='val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylim(0.7, 1)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  파일 길이 :  10000\n",
      "0  :  C:/Users/dltmd/jupyterSave/img/0\\food1.jpg\n",
      "1  파일 길이 :  7500\n",
      "1  :  C:/Users/dltmd/jupyterSave/img/1\\interior1.jpg\n",
      "2  파일 길이 :  5000\n",
      "2  :  C:/Users/dltmd/jupyterSave/img/2\\exterior1.jpg\n"
     ]
    }
   ],
   "source": [
    "directory = 'C:/Users/dltmd/jupyterSave/img'\n",
    "categories = [\"0\",\"1\",\"2\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "w = 300 \n",
    "h = 300\n",
    "pixels = w*h*3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, obj in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = directory + \"/\" + obj\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(obj, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((w, h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            print(obj, \" : \", f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok 22500\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "xy = (X_train, X_test, y_train, y_test, X_val, y_val)\n",
    "np.save(\"C:/Users/dltmd/jupyterSave/multi_image_data.npy\", xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, X_val, y_val = np.load(\"C:/Users/dltmd/jupyterSave/multi_image_data.npy\")\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "X_val = np.array(X_val)\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, input_shape=(300, 300, 3), \n",
    "                kernel_size=(3, 3), padding='same', activation='relu', name='conv_layer1')) \n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', name='conv_layer2')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(rate=0.5)) \n",
    "model.add(Conv2D(64, kernel_size=(3, 3), padding='same', activation='relu', name='conv_layer3')) \n",
    "model.add(Conv2D(128, kernel_size=(3, 3), padding='valid', activation='relu', name='conv_layer4')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(rate=0.5)) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512, activation='relu', name='hidden_layer1')) \n",
    "model.add(Dropout(rate=0.5)) \n",
    "model.add(Dense(256, activation='relu', name='hidden_layer2')) \n",
    "model.add(Dropout(rate=0.5)) \n",
    "model.add(Dense(3, activation='softmax', name='output_layer'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  8/144 [>.............................] - ETA: 34:07 - loss: 5104.5630 - accuracy: 0.3580"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-138fa6a9905c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m history = model.fit(\n\u001b[0;32m      5\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         callbacks=[early_stopping])\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습시키기\n",
    "early_stopping = EarlyStopping(patience = 15) # 조기종료 콜백함수 정의\n",
    "\n",
    "history = model.fit(\n",
    "        X_train, y_train, validation_data=(X_val, y_val), batch_size=100, epochs=10,\n",
    "        callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_curve(history)\n",
    "print(\"train loss=\", history.history['loss'][-1])\n",
    "print(\"validation loss=\", history.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn02\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('cnn02.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, input_shape=(300, 300, 3) ,kernel_size=(3, 3), \n",
    "                  activation='relu', name='conv_layer1'))\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model2.add(Conv2D(64, kernel_size=(3, 3), activation='relu', name='conv_layer2')) \n",
    "model2.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model2.add(Dropout(0.2)) \n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu', name='hidden_layer1')) \n",
    "model2.add(Dense(128, activation='relu', name='hidden_layer2')) \n",
    "model2.add(Dense(3, activation='softmax', name='output_layer'))\n",
    "\n",
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "144/144 [==============================] - 630s 4s/step - loss: 502.2911 - accuracy: 0.4873 - val_loss: 1.0185 - val_accuracy: 0.4931\n",
      "Epoch 2/10\n",
      "144/144 [==============================] - 625s 4s/step - loss: 0.7928 - accuracy: 0.6479 - val_loss: 0.8330 - val_accuracy: 0.6433\n",
      "Epoch 3/10\n",
      "144/144 [==============================] - 617s 4s/step - loss: 0.3618 - accuracy: 0.8680 - val_loss: 1.0500 - val_accuracy: 0.5611\n",
      "Epoch 4/10\n",
      "144/144 [==============================] - 615s 4s/step - loss: 0.4075 - accuracy: 0.8560 - val_loss: 1.2092 - val_accuracy: 0.6228\n",
      "Epoch 5/10\n",
      "144/144 [==============================] - 615s 4s/step - loss: 0.1229 - accuracy: 0.9610 - val_loss: 1.4780 - val_accuracy: 0.6236\n",
      "Epoch 6/10\n",
      "144/144 [==============================] - 616s 4s/step - loss: 0.0554 - accuracy: 0.9850 - val_loss: 2.0952 - val_accuracy: 0.6292\n",
      "Epoch 7/10\n",
      "144/144 [==============================] - 624s 4s/step - loss: 0.0353 - accuracy: 0.9906 - val_loss: 2.0897 - val_accuracy: 0.6239\n",
      "Epoch 8/10\n",
      "144/144 [==============================] - 625s 4s/step - loss: 0.0285 - accuracy: 0.9934 - val_loss: 2.0687 - val_accuracy: 0.6267\n",
      "Epoch 9/10\n",
      "144/144 [==============================] - 623s 4s/step - loss: 0.1065 - accuracy: 0.9679 - val_loss: 1.9765 - val_accuracy: 0.6369\n",
      "Epoch 10/10\n",
      "144/144 [==============================] - 621s 4s/step - loss: 0.0396 - accuracy: 0.9898 - val_loss: 2.6235 - val_accuracy: 0.6086\n"
     ]
    }
   ],
   "source": [
    "# 4. 모델 학습시키기\n",
    "early_stopping = EarlyStopping(patience = 15) # 조기종료 콜백함수 정의\n",
    "\n",
    "history2 = model2.fit(\n",
    "        X_train, y_train, validation_data=(X_val, y_val), batch_size=100, epochs=10,\n",
    "        callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAEKCAYAAAARqpPnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdeXwV5d3//9cnCwTCFghECFuQyGGRRSMiKKIIVati3cCf31ZplRv3pRVba9W2ai0uVW+tlnq7VSuhVm4t9VYOiFAR0SAoYFgDQmQLEPYty/X7Y07gEAKEbJNzzvvJ4zzOnLlmznwmIZN35lxzjTnnEBERERGJdXF+FyAiIiIiUh8oGIuIiIiIoGAsIiIiIgIoGIuIiIiIAArGIiIiIiKAgrGIiIiICKBgLCIS8czsFTPbZGaLjtJuZvacma0ws2/M7LSwtgvNbGmo7Zd1V7WISP2jYCwiEvleAy48RvtFQGboMQZ4EcDM4oEXQu09gGvNrEetVioiUo8pGIuIRDjn3Cxg6zEWGQG84TyfAy3MrC3QH1jhnMtzzh0AJoaWFRGJSQl+FwCQmprqOnfu7HcZIiJVMm/evM3OudZ+13EM6cDasNf5oXkVzT/zaG9iZmPwzjiTnJx8eiAQqPlKRURq2bGO2fUiGHfu3JmcnBy/yxARqRIz+87vGo7DKpjnjjG/Qs65CcAEgKysLKfjtohEomMds+tFMBYRkVqVD3QIe90eWAc0OMp8EZGYpD7GIiLR733gJ6HRKQYA251z64EvgUwzyzCzBsCo0LIiIjFJZ4xFRCKcmb0NDAFSzSwfeAhIBHDOvQR8AFwMrAD2AKNDbcVmdhvwERAPvOKcW1znOyAiUk8oGIuIRDjn3LXHaXfArUdp+wAvOFdbUVER+fn57Nu3rybeTqopKSmJ9u3bk5iY6HcpUkUlpSXsKdrDrgO72F20m90HdrO7aLf3Omz6QMkBzul4Dn1P6otZRZcOSGUpGIuISI3Iz8+nadOmdO7cWb+cfeacY8uWLeTn55ORkeF3OTFh94HdbN6z+bAQe9zpCkJu+PS+4hP7IzOzZSYje47kmp7X0KtNL/0cVoGCsYiI1Ih9+/YpFNcTZkarVq0oKCjwu5SoU+pKWb1tNd9s/IavN3zNN5u855WFKyu1frzF06RBE5IbJJOcmHxwOiUphQ7NOhw+PzGZ5AbHny51pXyw/AOyF2fz2KeP8ch/HqF7andG9hzJyF4jCaRqaMXKUjAWEZEao1Bcf+h7UX079+9k0aZFfL3xay8Ib/yahRsXsvPATgAMI7NVJv3a9uP6PteT3iz9uCG2QXyDWvne3HT6Tdx0+k1s3LWRd3PfJXtxNr+d+VsenvkwvdN6c02PaxjZayRdW3at8W37YU/RHr7f8T2ZrTJr9H0jNhhPmQKLF8N99/ldiYiIiESysrPAX284FIC/2fjNYWeBmzdsTu+03lzf53p6p/Wmz0l96Nm6J8kNkn2s/EhpTdK4+YybufmMm1m3cx3vfPsO2YuzeWDGAzww4wFOa3saI3uO5OoeV5OREjndbDbs2sDsNbOZvdZ7fLX+K05pdQqLb6nZ64UjNhhPnw4TJsC990KcBp0TERGRSti5fycLNy08rCvE0c4C39D3Bi8Ep/WhY/OOEXcWvl3Tdtxx5h3cceYdrN2+ln98+w+yF2dz37T7uG/affRP738wJHdo3uH4b1hHSl0puQW5B0Pw7DWzD/6RkpSQxBntzuAXZ/2CszueXePbjthgHAjAnj3w/ffQof58L0VEJMoVFxeTkBCxvz5jRqkrZVXhqsPOAH+98WvyCvMOLhMpZ4FrQofmHbjnrHu456x7WFW46mBI/vnUn/PzqT9nYIeBB0Ny26Zt67S2vUV7+eL7Lw4G4Tlr51C4rxCANsltGNRhEDdn3cygjoM4re1pNIhvUGu1ROxPdiDUj3zJEgVjERHxXH755axdu5Z9+/Zx5513MmbMGD788EPuv/9+SkpKSE1NZfr06ezatYvbb7+dnJwczIyHHnqIK6+8kiZNmrBr1y4A3nnnHaZMmcJrr73GDTfcQMuWLZk/fz6nnXYaI0eO5K677mLv3r00atSIV199lW7dulFSUsJ9993HRx99hJlx00030aNHD55//nkmT54MQDAY5MUXX+Tdd9/180sVdZxzfLTyI95b8h7fbPqGbzZ+w64D3vey7Czw6W1PZ3Tf0fRJ60PvtN4ReRa4JmSkZDBu0DjGDRrH8i3LmbR4EpO+ncSdH97JXR/exeBOgxnZcyRX9riSNsltanz7G3dtPHgmuKxbRFFpEQDdU7tzZfcrGdRxEGd3PJuTU06u0+9RVATjYcP8rUVERA5314d3sWDDghp9z74n9eWZC5855jKvvPIKLVu2ZO/evZxxxhmMGDGCm266iVmzZpGRkcHWrVsB+P3vf0/z5s1ZuHAhAIWFhcfd/rJly5g2bRrx8fHs2LGDWbNmkZCQwLRp07j//vv55z//yYQJE1i1ahXz588nISGBrVu3kpKSwq233kpBQQGtW7fm1VdfZfTo0dX/ggjgBeKPV33Mb2b8hjn5c2jWsBl90vpwQ58bDp4F7tWmF40TG/tdar2U2SqTXw/+Nb8e/GtyC3KZtHgS2YuzueWDW7jt/27jvM7nMbLnSK7ofgWtGrc64fevTLeIn5/1cwZ1HMRZ7c+q0jZqUsQG4zZtoEULLxiLiIgAPPfccwfPzK5du5YJEyYwePDgg2P5tmzZEoBp06YxceLEg+ulpKQc972vvvpq4uPjAdi+fTvXX389y5cvx8woKio6+L5jx4492NWibHs//vGPefPNNxk9ejRz5szhjTfeqKE9jm3/+e4//GbGb5j53UzaN2vPSz98idH9RtfqR+3RrHvr7jw05CEePPdBFm1adDAkj5kyhpv/fTMXdLmAkT1HcnngclIaVfwzs7doL1+u+5LZa2bz6dpPD+sW0bpxa87ueHaddYuoiogNxmbeWWMFYxGR+ud4Z3ZrwyeffMK0adOYM2cOjRs3ZsiQIfTp04elS5cesaxzrsKPZ8Pnlb+DX3LyoX6nv/nNbzjvvPOYPHkyq1evZsiQIcd839GjR3PppZeSlJTE1VdfrT7K1TQ3fy6/mfEbgnlB0pLTePbCZxlz+hiSEpL8Li0qmBmnpp3KqWmn8rvzfseCDQvIXpzNpMWT+On7P+W/pvwXP+j6A67pcQ1ndzyb+RvmH7dbxKAOg+jasmu977oS0T+ZgQBMnep3FSIiUh9s376dlJQUGjduzJIlS/j888/Zv38/M2fOZNWqVQe7UrRs2ZLhw4fz/PPP88wzXoAvLCwkJSWFtLQ0cnNz6datG5MnT6Zp06ZH3VZ6ejoAr7322sH5w4cP56WXXmLIkCEHu1K0bNmSdu3a0a5dOx555BGCwWCtfy2i1fz183nwkweZsmwKqY1TeWLYE9xyxi3qJlGLzIx+bfvRr20//jD0D+SsyzkYkqcsm3JwuYbxDTkjvX51i6iKiA/Gr70GO3ZAs2Z+VyMiIn668MILeemll+jduzfdunVjwIABtG7dmgkTJnDFFVdQWlpKmzZtCAaDPPDAA9x666306tWL+Ph4HnroIa644goef/xxLrnkEjp06ECvXr0OXohX3rhx47j++ut5+umnOf/88w/Ov/HGG1m2bBm9e/cmMTGRm266idtuuw2A6667joKCAnr06FEnX49osmjTIh765CHezX2XFkktePT8R7m9/+00bVjxHy5SO8yMM9LP4Iz0Mxg/bDxz8+cyf8N8+p3Uj9PankbDhIZ+l1ht5pzzuwaysrJcTk7OCa/33ntw+eXwxRdwxhm1UJiISCWY2TznXJbfddSlio7bubm5dO/e3aeK6r/bbruNfv368bOf/azOthnp35Olm5fy25m/ZeKiiTRp0IS7B9zN3WfdTYukFn6XJhHsWMfsiD9jDF4/YwVjERGpr04//XSSk5N56qmn/C4lIuQV5vG7mb/jb9/8jaSEJO4bdB+/GPiLiPxoXiJLRAfjLl0gIUEX4ImISP02b948v0uICGu2r+GRWY/w6oJXSYhL4M4z7+S+QfeR1iTN79IkRkR0ME5MhK5dFYxFREQi2fqd63nsP48x4asJOOf4r9P/i/vPuZ92Tdv5XZrEmOMGYzN7BbgE2OSc6xWa9wRwKXAAWAmMds5tC7X9CvgZUALc4Zz7qJZqBzRkm4iISKTatHsTf/z0j/w5588UlRQxuu9oHhj8AJ1adPK7NIlRcZVY5jXgwnLzgkAv51xvYBnwKwAz6wGMAnqG1vmzmcXXWLUVCARg+XIoLq7NrYiIiEhN2bp3K7+a9iu6PNuFZ+Y+wzU9r2HpbUv562V/VSgWXx33jLFzbpaZdS43L3z04M+Bq0LTI4CJzrn9wCozWwH0B+bUSLUVCASgqAhWrYLMzNraioiIiFTX9n3b+dPnf+LpOU+z68AuRvYayUPnPkQgNeB3aSJAzfQx/imQHZpOxwvKZfJD82pN+MgUCsYiIiL1z64Du3hu7nM8+dmTFO4r5EeBH/HbIb/l1LRT/S5N5DDVCsZm9mugGHirbFYFi1U4ULKZjQHGAHTs2LHKNXTr5j0vWQKXXlrltxERkRjTpEmTo97AQ2rGnqI9/PnLP/PH2X9k857N/DDzh/zuvN9xWtvT/C5NpEJVDsZmdj3eRXlD3aG7hOQDHcIWaw+sq2h959wEYAJ4A8VXtY4WLeCkk3QBnoiIRKbi4mISEiJ6kKgj7Cvex4R5E/jDp39gw64NDOsyjN+d9zsGtB/gd2kix1Sln0QzuxC4DzjXObcnrOl94O9m9jTQDsgEvqh2lcehkSlEROqfIUOGHDHvmmuu4ZZbbmHPnj1cfPHFR7TfcMMN3HDDDWzevJmrrrrqsLZPPvnkmNu777776NSpE7fccgsADz/8MGbGrFmzKCwspKioiEceeYQRI0Yct/Zdu3YxYsSICtd74403ePLJJzEzevfuzd/+9jc2btzI2LFjycvLA+DFF1+kXbt2XHLJJSxatAiAJ598kl27dvHwww8zZMgQBg4cyOzZs7nssss45ZRTeOSRRzhw4ACtWrXirbfeIi0tjV27dnH77beTk5ODmfHQQw+xbds2Fi1axJ/+9CcA/vrXv5Kbm8vTTz993P2qC4s2LeKity4if0c+gzsNJvuqbAZ3Gux3WSKVUpnh2t4GhgCpZpYPPIQ3CkVDIGhmAJ8758Y65xab2STgW7wuFrc650pqq/gygQBkZ4NzYBV15hARkag3atQo7rrrroPBeNKkSXz44YfcfffdNGvWjM2bNzNgwAAuu+wy7Di/LJKSkpg8efIR63377bc8+uijzJ49m9TUVLZu3QrAHXfcwbnnnsvkyZMpKSlh165dFBYWHnMb27ZtY+bMmQAUFhby+eefY2a8/PLLjB8/nqeeeorf//73NG/enIULFx5crkGDBvTu3Zvx48eTmJjIq6++yl/+8pfqfvlqzAMfP8DuA7sJ/jjI0Iyhx/1ai9QnlRmV4toKZv/PMZZ/FHi0OkWdqEAACgth82Zo3boutywiIkdzrDO8jRs3PmZ7amrqcc8Ql9evXz82bdrEunXrKCgoICUlhbZt23L33Xcza9Ys4uLi+P7779m4cSMnnXTSMd/LOcf9999/xHoff/wxV111FampqQC0bNkSgI8//pg33ngDgPj4eJo3b37cYDxy5MiD0/n5+YwcOZL169dz4MABMjIyAJg2bRoTJ048uFxKSgoA559/PlOmTKF79+4UFRVx6qn14yK23IJc3lv6Hg8OfpALulzgdzkiJywqOjWFj0yhYCwiEruuuuoq3nnnHTZs2MCoUaN46623KCgoYN68eSQmJtK5c2f27dt33Pc52nrOuUqfAU1ISKC0tPTg6/LbTU5OPjh9++23c88993DZZZfxySef8PDDDwMcdXs33ngjjz32GIFAgNGjR1eqnrrw5GdP0iihEbf1v83vUkSqpDI3+Kj3woOxiIjErlGjRjFx4kTeeecdrrrqKrZv306bNm1ITExkxowZfPfdd5V6n6OtN3ToUCZNmsSWLVsADnalGDp0KC+++CIAJSUl7Nixg7S0NDZt2sSWLVvYv38/U6ZMOeb20tO90U1ff/31g/OHDx/O888/f/B12VnoM888k7Vr1/L3v/+da6+t6IPduvf9ju/52zd/46f9fkrrZJ2lksgUFcG4Qwdo1Ahyc/2uRETEH2Z2oZktNbMVZvbLCtpTzGyymX1jZl+YWa+wttVmttDMFphZTt1WXrN69uzJzp07SU9Pp23btlx33XXk5OSQlZXFW2+9RSBQuRtJHG29nj178utf/5pzzz2XPn36cM899wDw7LPPMmPGDE499VROP/10Fi9eTGJiIg8++CBnnnkml1xyyTG3/fDDD3P11VdzzjnnHOymAfDAAw9QWFhIr1696NOnDzNmzDjYds011zBo0KCD3Sv89uzcZylxJdxz1j1+lyJSZXZopDX/ZGVluZyc6h2L+/WDtm3hgw9qqCgRkUoys3nOuSwftx8PLAOG4Q2b+SVwrXPu27BlngB2Oed+a2YB4AXn3NBQ22ogyzm3ubLbrOi4nZubS/fu3au7O1JJl1xyCXfffTdDhw496jJ19T3Ztm8bHf/UkR+e8kPevvLtWt+eSHUc65gdFWeMQUO2iUhM6w+scM7lOecOABOB8mOS9QCmAzjnlgCdzSytbsuUmrBt2zZOOeUUGjVqdMxQXJf+kvMXdh7YybiB4/wuRaRaouLiOzg0ZNvevV63ChGRGJIOrA17nQ+cWW6Zr4ErgE/NrD/QCe8mTBvx7lA61cwc8JfQDZhiwsKFC/nxj3982LyGDRsyd+5cnyo6vhYtWrBs2TK/yzhoX/E+npn7DMO6DKNf235+lyNSLVEVjJ2D5cuhd2+/qxERqVMVDZNQvp/c48CzZrYAWAjMxxtvHmCQc26dmbXBG59+iXNu1hEbMRsDjAHo2LFjhYWcyKgN9cGpp57KggUL/C6jVtRVV8k3v3mTDbs28Lcf/a1OtidSm6KqKwWoO4WIxKR8oEPY6/bAuvAFnHM7nHOjnXN9gZ8ArYFVobZ1oedNwGS8rhlHcM5NcM5lOeeyWlcwNmZSUhJbtmyps0AmR+ecY8uWLSQlJdXqdkpKS3jisyfod1I/hmbUj24dItURNWeMMzO9u94pGItIDPoSyDSzDOB7YBTw/4UvYGYtgD2hPsg3ArOcczvMLBmIc87tDE0PB35XlSLat29Pfn4+BQUF1dkXqSFJSUm0b9++Vrfx/tL3WbZlGROvnBhRnxSIHE3UBOPGjaFTJwVjEYk9zrliM7sN+AiIB15xzi02s7Gh9peA7sAbZlYCfAv8LLR6GjA5FGoSgL875z6sSh2JiYkH79gm0c85xx9n/5GMFhlc2eNKv8sRqRFRE4xBI1OISOxyzn0AfFBu3kth03OAzArWywP61HqBEnX+s+Y/zP1+Li9c/AIJcVEVJySGRU0fY/CC8dKlEHYHThEREakF42ePJ7VxKjf0vcHvUkRqTNQF4z17ID/f70pERESi16JNi/j38n9zR/87aJzY2O9yRGpM1AVjUHcKERGR2vTEZ0/QOLExt5xxi9+liNQoBWMRERGptDXb1/D3hX/nptNuolXjVn6XI1KjoioYt2kDKSkKxiIiIrXlmc+fwTnH3QPu9rsUkRoXVcHYTCNTiIiI1Jate7cyYd4Erj31Wjq16OR3OSI1LqqCMSgYi4iI1JYXv3yR3UW7uXfgvX6XIlIrojIYr18P27f7XYmIiEj02Fu0l2fnPstFXS+id1pvv8sRqRVRGYzBG89YREREasbrX79OwZ4Cxg0a53cpIrUmaoOxulOIiIjUjJLSEp787En6p/fn3E7n+l2OSK2JumCckQGJiQrGIiIiNeXd3HdZWbiScQPHYWZ+lyNSa44bjM3sFTPbZGaLwua1NLOgmS0PPaeEtf3KzFaY2VIz+0FtFX40iYnQtauCsYiISE1wzvHH2X8ks2Umlwcu97sckVpVmTPGrwEXlpv3S2C6cy4TmB56jZn1AEYBPUPr/NnM4mus2krSyBQiIiI1Y8bqGcxbP49fDPwF8XF1/itdpE4dNxg752YBW8vNHgG8Hpp+Hbg8bP5E59x+59wqYAXQv4ZqrbRAAFasgKKiut6yiIhIdBk/ezxpyWn8pM9P/C5FpNZVtY9xmnNuPUDouU1ofjqwNmy5/NC8I5jZGDPLMbOcgoKCKpZRsUDAC8WrVtXo24qIiMSUBRsW8NHKj7jzzDtJSkjyuxyRWlfTF99V1CPfVbSgc26Ccy7LOZfVunXrGi1CI1OIiIhU3xOfPUGTBk0YmzXW71JE6kRVg/FGM2sLEHreFJqfD3QIW649sK7q5VVNt27es4KxiIhI1azetprsRdn81+n/RUqjlOOvIBIFqhqM3weuD01fD7wXNn+UmTU0swwgE/iieiWeuObNoW1bBWMREZGqenrO08RZHHcNuMvvUkTqTMLxFjCzt4EhQKqZ5QMPAY8Dk8zsZ8Aa4GoA59xiM5sEfAsUA7c650pqqfZj0sgUIiIiVbN5z2Ze/uplrut9He2btfe7HJE6c9xg7Jy79ihNQ4+y/KPAo9UpqiYEAjBxIjgHGotcRESk8l744gX2Fu/l3oH3+l2KSJ2KujvflQkEoLAQanjACxERkai2+8Bu/vuL/+bSUy6lR+sefpcjUqeiOhiDulOIiIiciFcXvMqWvVsYN2ic36WI1DkFYxEREQGguLSYp+Y8xcAOAzm749l+lyNS56I2GLdvD40bKxiLiIhU1j8W/4PV21YzbqDOFktsitpgHBfnjWesYCwiInJ8zjnGfzaeQGqAS7td6nc5Ir6I2mAMGrJNRESksoJ5QRZsWMC9A+8lzqI6HogcVVT/zw8EYPVq2LvX70pERETqt/Gzx9OuaTuuO/U6v0sR8U3UB2PnYPlyvysRERGpv+atm8f0VdO568y7aJjQ0O9yRHwT9cEY1J1CRKKfmV1oZkvNbIWZ/bKC9hQzm2xm35jZF2bWq7LrSvQb/9l4mjVsxpjTx/hdioivojoYZ2Z6d71TMBaRaGZm8cALwEVAD+BaMyt/Z4b7gQXOud7AT4BnT2BdiWIrt67knW/f4easm2me1NzvckR8FdXBuFEj6NxZwVhEol5/YIVzLs85dwCYCIwot0wPYDqAc24J0NnM0iq5rkSxp+Y8RUJcAneeeaffpYj4LqqDMWhkChGJCenA2rDX+aF54b4GrgAws/5AJ6B9JdcltN4YM8sxs5yCgoIaKl38tGn3Jl5d8Co/6f0T2jZt63c5Ir6LiWC8dCmUlvpdiYhIrbEK5rlyrx8HUsxsAXA7MB8oruS63kznJjjnspxzWa1bt65OvVJP/Pfc/2Z/8X5+MfAXfpciUi8k+F1AbQsEYM8eyM+Hjh39rkZEpFbkAx3CXrcH1oUv4JzbAYwGMDMDVoUejY+3rkSnXQd28cKXL3B54HK6pXbzuxyReiEmzhiDulOISFT7Esg0swwzawCMAt4PX8DMWoTaAG4EZoXC8nHXlej08lcvU7ivkHGDdPtnkTIKxiIiEc45VwzcBnwE5AKTnHOLzWysmY0NLdYdWGxmS/BGoLjzWOvW9T5I3SoqKeLpOU8zuNNgBrQf4Hc5IvVG1HelaN0aUlIUjEUkujnnPgA+KDfvpbDpOUBmZdeV6DZx0UTW7ljLiz980e9SROqVqD9jbKaRKURERMo45xj/2Xh6tenFxZkX+12OSL0S9cEYFIxFRETK/N+K/2PRpkXcO/BevOswRaRMzATj9eth+3a/KxEREfHX+Nnj6dCsA9f2utbvUkTqnZgJxuCNZywiIhKr5ubPZeZ3M7l7wN0kxif6XY5IvVOtYGxmd5vZYjNbZGZvm1mSmbU0s6CZLQ89p9RUsVWlkSlERERg/GfjSUlK4abTb/K7FJF6qcrB2MzSgTuALOdcLyAeb/zLXwLTnXOZwPTQa19lZEBiooKxiIjErqWblzI5dzK3nHELTRo08bsckXqpul0pEoBGZpaAd/ekdcAI4PVQ++vA5dXcRrUlJkLXrgrGIiISu56a8xQN4htwe//b/S5FpN6qcjB2zn0PPAmsAdYD251zU4E059z60DLrgTYVrW9mY8wsx8xyCgoKqlpGpQUCkJtb65sRERGpd9bvXM/rX7/O6L6jSWuS5nc5IvVWdbpSpOCdHc4A2gHJZvb/Kru+c26Ccy7LOZfVunXrqpZRaYEArFgBRUW1vikREZF65bm5z1FcWszPB/7c71JE6rXqdKW4AFjlnCtwzhUB7wIDgY1m1hYg9Lyp+mVWXyAAxcWQl+d3JSIiInVnx/4dvJjzIld2v5KuLbv6XY5IvVadYLwGGGBmjc0bIXwokAu8D1wfWuZ64L3qlVgzNDKFiIjEognzJrB9/3bGDRrndyki9V51+hjPBd4BvgIWht5rAvA4MMzMlgPDQq99162b96xgLCIisWJ/8X7+9PmfOD/jfLLaZfldjki9l1CdlZ1zDwEPlZu9H+/scb3SvDm0batgLCIisePvC//Oup3reOWyV/wuRSQixMSd78oEAgrGIiISG0pdKU989gR90vow/OThfpcjEhFiMhg753clIiIitWvKsinkbs5l3KBxeJcCicjxxFww3rYNNtWLcTJERERqx77ifTz+6eN0at6Ja3pe43c5IhGjWn2MI034yBRpGt9cRESiyIGSAwRXBslenM3/Lvlfdh7YyYs/fJGEuJj6VS9SLTH10xIejM89199aREREqqu4tJgZq2aQvTibd3PfpXBfIS2SWnB1j6sZ1WsUF3S5wO8SRSJKTAXj9u2hcWNdgCciIpGrpLSE/6z5D9mLsvln7j8p2FNA0wZNGREYwcieIxl+8nAaxDfwu0yRiBRTwTguzhvPWMFYREQiSakr5fP8z5m4aCLvfPsO63etp3FiYy495VJG9hzJRZkXkZSQ5HeZIhEvpoIxQPfu8NlnflchIiJybM45ctblkL04m0mLJ7F2x1oaxjfk4syLGdlzJJeccgnJDZL9LlMkqsRcMA4E4O23Yc8er1PKtP0AAB8cSURBVFuFiIhIfeGc45uN35C9OJvsxdnkFeaRGJfID7r+gMeGPsZl3S6jWcNmfpcpErViMhg7B8uXQ58+flcjIiIC3xZ8S/YiLwwv3bKUeItnaJeh/PqcX/OjwI9IaZTid4kiMSEmgzF4/YwVjEVExC8rtq4ge1E2ExdPZNGmRRjGkM5DuHvA3VzR/QpaJ7f2u0SRmBNzwTgzE8x0AZ6IiNS91dtWM2nxJLIXZ/PV+q8AGNRhEM9d+BxX9biKtk3b+lyhSGyLuWCclAQZGQrGIiJSN77f8T3/+PYfZC/O5vP8zwHon96fp4Y/xdU9rqZD8w4+VygiZWIuGIPXnULBWEREatst/76Fl3JewuHoe1Jf/jD0D1zT8xq6pHTxuzQRqUDMBuMZM6C01BvbWEQk0pnZhcCzQDzwsnPu8XLtzYE3gY54x/4nnXOvhtpWAzuBEqDYOZdVh6VHrcK9hfxl3l+4sseVPHr+o5zS6hS/SxKR44jJWBgIwN69sHat35WIiFSfmcUDLwAXAT2Aa82sR7nFbgW+dc71AYYAT5lZ+O3RznPO9VUorjkfr/qYUlfKXWfepVAsEiFiNhiDulOISNToD6xwzuU55w4AE4ER5ZZxQFMzM6AJsBUortsyY0swL0jTBk3pn97f71JEpJIUjEVEIl86EP4ZWH5oXrjnge7AOmAhcKdzrjTU5oCpZjbPzMYcbSNmNsbMcswsp6CgoOaqj1JTV07lvIzzSIxP9LsUEamkmAzGqanQsqWCsYhEDatgniv3+gfAAqAd0Bd43szKbqE2yDl3Gl5XjFvNbHBFG3HOTXDOZTnnslq31hi7x7Jy60pWbVvFsC7D/C5FRE5ATAZjM41MISJRJR8IH/OrPd6Z4XCjgXedZwWwCggAOOfWhZ43AZPxumZINQTzggAKxiIRJiaDMSgYi0hU+RLINLOM0AV1o4D3yy2zBhgKYGZpQDcgz8ySzaxpaH4yMBxYVGeVR6lgXpAOzTroojuRCBPTwXjDBti2ze9KRESqxzlXDNwGfATkApOcc4vNbKyZjQ0t9ntgoJktBKYD9znnNgNpwKdm9jXwBfBv59yHdb8X0aOktISPV33M8JOH413rKCKRolrjGJtZC+BloBdef7afAkuBbKAzsBq4xjlXWK0qa0HZBXhLl8KZZ/pbi4hIdTnnPgA+KDfvpbDpdXhng8uvlwf0qfUCY0jOuhy27dumbhQiEai6Z4yfBT50zgXwDqy5wC+B6c65TLyzEr+s5jZqhUamEBGR2hDMC2IYQ7sM9bsUETlBVQ7GoauZBwP/A+CcO+Cc24Y3dubrocVeBy6vbpG1ISMDEhMVjEVEpGYF84L0a9uP1MapfpciIieoOmeMuwAFwKtmNt/MXg5duJHmnFsPEHpuU9HKfo+HmZAAmZkKxiIiUnN2HdjFnLVz1I1CJEJVJxgnAKcBLzrn+gG7OYFuE/VhPEyNTCEiIjVp5uqZFJUWKRiLRKjqBON8IN85Nzf0+h28oLzRzNoChJ43Va/E2hMIwIoVUFTkdyUiIhINpq6cSlJCEoM6DvK7FBGpgioHY+fcBmCtmXULzRoKfIs3dub1oXnXA+9Vq8JaFAhAcTHk5fldiYiIRINgXpDBnQaTlJDkdykiUgXVGq4NuB14KzSgfB7enZXigElm9jO8AeWvruY2ak34yBTduh17WRERkWPJ35FP7uZcftrvp36XIiJVVK1g7JxbAGRV0BQRY9SUheElS2DECH9rERGRyDYtbxqg20CLRLKYvfMdQLNm0K6dLsATEZHqC+YFaZPchlPTTvW7FBGpopgOxqCRKUREpPpKXSnT8qYxrMsw4izmf7WKRKyY/+ktC8bO+V2JiIhEqoUbF7Jp9yZ1oxCJcArGAdi2DTbV20HlRESkvgvmBQG4oMsFPlciItWhYBw2MoWIiEhVBPOC9Gjdg/Rm6X6XIiLVoGCsYCwiItWwr3gfs76bpW4UIlEg5oNxejokJysYi4hI1Xy65lP2Fe9TMBaJAjEfjOPivPGMFYxFRKQqgiuDJMYlcm7nc/0uRUSqKeaDMWjINhERqbpgXpCzOpxFkwZN/C5FRKpJwRgvGH/3HezZ43clIiISSQp2FzB/w3x1oxCJEgrGeMHYOVi+3O9KREQkkkxfNR3QbaBFooWCMRqZQkREqia4MkiLpBZktcvyuxQRqQEKxkBmJpgpGIuISOU55wjmBRmaMZT4uHi/yxGRGqBgDCQlQUaGgrGIiFTesi3LWLtjrbpRiEQRBeMQjUwhIiInouw20MNOVjAWiRYKxiGBACxdCqWlflciIiKRIJgXpEtKF7qkdPG7FBGpIQrGIYEA7N0La9b4XYmIiNR3RSVFzFg1Q90oRKKMgnGIRqYQEZHKmvv9XHYe2KlgLBJlFIxDFIxFRKSygiuDxFkc52ec73cpIlKDFIxDUlOhZUsFYxGJTGZ2oZktNbMVZvbLCtqbm9m/zOxrM1tsZqMru64cKZgXJKtdFimNUvwuRURqkIJxiJlGphCRyGRm8cALwEVAD+BaM+tRbrFbgW+dc32AIcBTZtagkutKmO37tvPF91+oG4VIFKp2MDazeDObb2ZTQq9bmlnQzJaHniPmz2kFYxGJUP2BFc65POfcAWAiMKLcMg5oamYGNAG2AsWVXFfCzFg9gxJXwvCTh/tdiojUsJo4Y3wnkBv2+pfAdOdcJjA99DoiBAKwcSMUFvpdiYjICUkH1oa9zg/NC/c80B1YBywE7nTOlVZyXQDMbIyZ5ZhZTkFBQU3VHnGCK4MkJyYzoP0Av0sRkRpWrWBsZu2BHwIvh80eAbwemn4duLw626hLZRfgLV3qbx0iIifIKpjnyr3+AbAAaAf0BZ43s2aVXNeb6dwE51yWcy6rdevW1ak3ogXzggzpPIQG8Q38LkVEalh1zxg/A4wDwm+LkeacWw8Qem5T0Yr18cyDRqYQkQiVD3QIe90e78xwuNHAu86zAlgFBCq5roR8t+07lm9drv7FIlGqysHYzC4BNjnn5lVl/fp45iEjAxITFYxFJOJ8CWSaWYaZNQBGAe+XW2YNMBTAzNKAbkBeJdeVEN0GWiS6JVRj3UHAZWZ2MZAENDOzN4GNZtbWObfezNoCm2qi0LqQkACZmQrGIhJZnHPFZnYb8BEQD7zinFtsZmND7S8BvwdeM7OFeN0n7nPObQaoaF0/9iMSTF05lXZN29E9tbvfpYhILahyMHbO/Qr4FYCZDQF+4Zz7f2b2BHA98Hjo+b0aqLPOBAKwWL8SRCTCOOc+AD4oN++lsOl1QIXDKFS0rhyppLSE6aumc+kpl+IN7iEi0aY2xjF+HBhmZsuBYaHXESMQgJUroajI70pERKQ+mb9hPlv3blX/YpEoVp2uFAc55z4BPglNbyHUjy0Sde8OxcVeOC67GE9ERCS40utffEGXC3yuRERqi+58V45GphARkYoE84L0TutNWpM0v0sRkVqiYFxOt27es4KxiIiU2VO0h9lrZ6sbhUiUUzAup2lTSE9XMBYRkUNmfTeLAyUHdBtokSinYFyBQEDBWEREDgmuDNIwviHndDzH71JEpBYpGFegLBi7Cm+KKiIisSaYF+TsjmfTKLGR36WISC1SMK5AIADbt8PGjX5XIiIiflu/cz0LNy1U/2KRGKBgXAGNTCEiImWm5U0DdBtokVigYFwBBWMRESkTzAuS2jiVvif19bsUEallCsYVSE+H5GQFYxGRWOecY1reNIZmDCXO9CtTJNrpp7wCZhqZQkREYHHBYtbvWq/+xSIxQsH4KBSMRUSk7DbQ6l8sEhsUjI8iEIDvvoM9e/yuRERE/BLMC3JKq1Po2Lyj36WISB1QMD6Ksgvwli3ztw4REfHH/uL9zPxuJsO76G53IrFCwfgoNDKFiEhsm5M/hz1Fe9SNQiSGKBgfRdeuEBenYCwiEquCK4PEWzxDOg/xuxQRqSMKxkeRlAQZGQrGIiKxKpgXZED7ATRr2MzvUkSkjigYH4NGphARiU1b9mwhZ12OhmkTiTEKxscQCMDSpVBa6nclIiJSlz5e9TEOp/7FIjFGwfgYAgHYtw/WrPG7EhERqUvBvCDNGjajf3p/v0sRkTqkYHwMGplCRCT2OOcI5gU5r/N5JMQl+F2OiNQhBeNjUDAWEYk9KwtXsnrbavUvFolBVQ7GZtbBzGaYWa6ZLTazO0PzW5pZ0MyWh55Taq7cupWaCq1aKRiLiMQS3QZaJHZV54xxMfBz51x3YABwq5n1AH4JTHfOZQLTQ68jlkamEBGJLcG8IB2bdySzZabfpYhIHatyMHbOrXfOfRWa3gnkAunACOD10GKvA5dXt0g/KRiLiMSO4tJiPl71McO7DMfM/C5HROpYjfQxNrPOQD9gLpDmnFsPXngG2tTENvwSCMDGjVBY6HclIiJS23LW5bB9/3Z1oxCJUdUOxmbWBPgncJdzbscJrDfGzHLMLKegoKC6ZdSasgvwli71tw4RkWMxswvNbKmZrTCzI7qwmdm9ZrYg9FhkZiVm1jLUttrMFobacuq++vojuDKIYQzNGOp3KSLig2oFYzNLxAvFbznn3g3N3mhmbUPtbYFNFa3rnJvgnMtyzmW1bt26OmXUKo1MISL1nZnFAy8AFwE9gGtD13wc5Jx7wjnX1znXF/gVMNM5tzVskfNC7Vl1Vng9NDVvKqe1PY1WjVv5XYqI+KA6o1IY8D9ArnPu6bCm94HrQ9PXA+9VvTz/de4MDRooGItIvdYfWOGcy3POHQAm4l3vcTTXAm/XSWURZOf+nXye/7mGaROJYdU5YzwI+DFwftjHcxcDjwPDzGw5MCz0OmIlJEBmpoKxiNRr6cDasNf5oXlHMLPGwIV4n/aVccBUM5tnZmNqrcp67pPVn1BcWqz+xSIxrMq39HHOfQoc7ZLdqOqcFQjAokV+VyEiclQVHYvdUZa9FJhdrhvFIOfcOjNrAwTNbIlzbtYRG/FC8xiAjh07VrfmeieYF6RRQiMGdRjkdyki4hPd+a4SAgFYuRKKivyuRESkQvlAh7DX7YF1R1l2FOW6UTjn1oWeNwGT8bpmHCFSrg2pqmBekMGdBtMwoaHfpYiITxSMKyEQgOJiLxyLiNRDXwKZZpZhZg3wwu/75Rcys+bAuYRd+2FmyWbWtGwaGA7E3Gdk+TvyWbJ5ifoXi8S4KneliCXhI1OUTYuI1BfOuWIzuw34CIgHXnHOLTazsaH2l0KL/giY6pzbHbZ6GjA5dDOLBODvzrkP6676+kG3gRYRUDCulG7dvGddgCci9ZVz7gPgg3LzXir3+jXgtXLz8oA+tVxevRfMC5KWnMapbU71uxQR8ZG6UlRC06aQnq5gLCISjUpdKdPypjHs5GG6DbRIjFMwrqRAQMFYRCQafbPxGwr2FKh/sYgoGFdWWTB2RxsASUREItLUlVMBuKDLBT5XIiJ+UzCupEAAtm+HjRv9rkRERGpSMC9Iz9Y9ade0nd+liIjPFIwrqWw0itxcf+sQEZGas7doL//57j/qRiEigIJxpYUP2SYiItHh0zWfsr9kv4ZpExFAwbjS0tMhOVnBWEQkmgTzgiTGJXJup3P9LkVE6gEF40oy08gUIiLRJpgXZGCHgSQ3SPa7FBGpBxSMT4CCsYhI9Ni0exMLNixQ/2IROUjB+AQEArBmDezeffxlRUSkfpueNx3QbaBF5BAF4xNQdgHesmX+1iEiItUXzAuSkpTC6W1P97sUEaknFIxPgEamEBGJDs45gnlBhnYZSnxcvN/liEg9oWB8Arp2hbg4BWMRkUi3ZPMS8nfkq3+xiBxGwfgEJCVBRoaCsYhIpAvmBQEUjEXkMArGJ0gjU4iIRL5gXpCTU04mIyXD71JEpB5RMD5BgYB38V1Jid+ViIhIVRSVFPHJ6k90tlhEjpDgdwGRJhCAffu8YdsydKJBpO7t3Qs7dng/iPv2ea/37YOsLEhIgEWLvEfZ/LLHffd5FwlkZ8P06YevD/Cvf/m7X1JnPs//nF0HdmmYNhE5goLxCere3XteskTBuNY5B6WlUFwMRUVw4AC0bOm1rV0LBQWHB5+4OLjwQq/9X/+CFSsOte3fDykpXjgCePBB+OYbb37ZMqecAq+/7rWffz4sWODNLy315g0ZAh9+6E337Al5eYfXe+mlMGmSN92pE2zadHj7tdfCK694061aHQpkZW68EZ57zvs4omnTI78ed98Njz4K27d79ygvY+Y9P/CAt3/ff3/oP2p4+x/+ALfcAkuXwplnHtn+3HPw4x/DvHkwbJg3P/wxYQJcfjl8+imMHOnNi4s71P7qq3DeeRAMws03H9n+5ptw+ukwZQrcf/+R7//229Ctm/f8yCOHB9u9eyE3Fzp3hmee8dYvr6AAUlO99R97rOKvX1ISfP21V0NS0qFHsu56FkuCeUHiLI7zM873uxQRqWdqLRib2YXAs0A88LJz7vEa38hHH8GuXRAf7/0CjouDtDQ44wyv/bPPvEBV1hYf7/3i7NrVa1+0yAtf4e3Nm3vvAZCff6gt1B7o2AhozJJcx0VnFnohpqTEC09lgaZFCy/MrVhxeFtJiRdoTjoJ9uyBnJwj1+/ZEzp2hMJC76xW+LolJXDOOdClC6xb54W/svbSUu9x2WVe+4oV8M9/Htl+/fVeov/6a5g48fC20lK45x5v+59+Cm+9dWT7H/4Abdt62371Va+9uPjQc3a2F/pefhn++tfD20pKvH1OTvaCz0svHd5eWgrbtnkhaexY+MtfDv9+N23qnSkEGDfOqz9c27be1wW8EDdlyqG2hg2hR49DwXj1ali1ygtFDRt6752Scmj5oUOhVy+vLT40lNPJJx9q/8lPYOvWw7ffo8eh6Rtv9P5vhuvX79D02LHe/81wAwZ4z2Zw220cYeBA77lBA2998P7/ln//xo297Zdv79nTe27eHG644cj2sp+L1FS47jqvLfzRoYPX3rIlXHTRofmlpd5z2R8tKSle8C7fXhY+mzTxvpbl379Bg0Pv37Pn4cE1PLz+4Afez1h4W6NGh/6YuOMO7/tTfv2y93/ssYqDs8SMYF6QM9qdQYukFn6XIiL1jLnwX4w19aZm8cAyYBiQD3wJXOuc+7ai5bOyslxOTs6JbygQ8M5+hbv4Yvj3v73p9PRDQanMNdd44Q2gWTPYufPw9p/9zAt14IXh8l+fu+6i9Zt/onHpLr7beuRZvdc7P8hbmb+ldfF63prR7oj27KzxTOt7L213Led3E085on3KD19kwYCxpG/8itHPHzno/Kwxb7Jq4HWkLZnJhY8POaJ9xl3v8f3pl5E+fwrnPX3pEe3T75/Opl7n03FONgNe/AnO4nBx3h8WzuL45Dcfs63LaXT8z5v0/dvPcRYHoWWcGbN/O5197bvS8ZM3OHnyE7j4BC84hp6X/vF/camtaf3Rm7T68C1IiMfi472PuBPi2fLka8Q1aUyTf2eT9GkQi4/HEhOwhHgsIZ7iPz5FfGIcCR+8T9z8eVhC2boJXjC69VZvR774AjZsOBR6Gjb02nv18trLAnbDhl4gilN3eqk9ZjbPOZfldx11qcrHbZ9t27eNVuNbcf/Z9/P783/vdzki4oNjHbNrKxifBTzsnPtB6PWvAJxzf6ho+SofYJcv9z5iDT8r2qyZ93EswJw5hz4KL2tPSzt0Zu1f//I+ng9v79Ll0Jm7l18+8oxrnz689O1gZk4rYujyFykpjaOoNJ5iF09xaRxLGp9GbqPTiDuwj3M2T6aoNN57lHjL5cb1JM9OJrFoD/32zeFASfzBR1FJHCtdBptII4m9dGUFJcRTShwlxFNCPJtow26a0ID9tGQrpcQdbC8ljt0kU0wi8RSTSNFh7Q4D7MS/zj4yO/SBQPlP3svaj/a6ppcJr6mi6WO11cR7nKjqrFum7GRu2fSx5p3o8kd7j6PtQ/j3pqbby55HjvR6q5woBePIMTl3MldMuoJZN8zinE7n+F2OiPjgWMfs2upKkQ6sDXudD5wZvoCZjQHGAHTs2LFqW8nMPHb7WWcdu/3SI8+oHqbs4+hyxg6GsWMTgTuOsXIScO0x2hsDQ4+Y61xZz4JGFBefSnExhz0OffreEOfaHlwnfH3vOYGyb2/F7Sc+r+xvg/CeHdV9VPb9yj6NLx+ojva6ppcp/3UpP32stpp4jxNV3b93nTvyj4Sy6WPNO9Hlj/Ye5ffhWP9Hq9sePq9LFyTKBfOCNGnQhAHtB/hdiojUQ7UVjCs6V3XYr2rn3ARgAnhnHmqpjohjdqjngIiI1KypK6cypPMQEuMT/S5FROqh2up4mQ90CHvdHlh3lGVFRERq3arCVawsXKnxi0XkqGorGH8JZJpZhpk1AEYB79fStkRERI5Lt4EWkeOplQ/snXPFZnYb8BHecG2vOOcW18a2REREKiOYFyS9aTqB1IDfpYhIPVVrPVmdcx8AH9TW+4uIiFRWSWkJ0/OmMyIwAquJIVtEJCppcFcREYl6X63/isJ9hepGISLHpGAsIhIFzOxCM1tqZivM7JcVtN9rZgtCj0VmVmJmLSuzbjQo6198QZcLfK5EROozBWMRkQgXutvoC8BFQA/gWjPrEb6Mc+4J51xf51xf4FfATOfc1sqsGw2CeUH6pPWhTXIbv0sRkXpMwVhEJPL1B1Y45/KccweAicCIYyx/LfB2FdeNOLsP7Gb2mtnqRiEix1UvbiMxb968zWb2XRVWTQU213Q9ESAW9zsW9xlic78jcZ87+bz9495ttIyZNQYuBG6rwroH71gK7DKzpSdYp6/f2ydD/3wQif+nqysW9xlic78jcZ+PesyuF8HYOde6KuuZWc7R7nUdzWJxv2NxnyE29zsW97kGHPduo2EuBWY757ae6Lrhdyytilj93sbifsfiPkNs7ne07bO6UoiIRL4TudvoKA51ozjRdUVEopqCsYhI5KvU3UbNrDlwLvDeia4rIhIL6kVXimqo8kd6ES4W9zsW9xlic79jcZ+r5Wh3GzWzsaH2l0KL/giY6pzbfbx1a6nUWP3exuJ+x+I+Q2zud1Ttszl3tG5oIiIiIiKxQ10pRERERERQMBYRERERASI4GMfCLUzDmVkHM5thZrlmttjM7vS7prpiZvFmNt/MpvhdS10xsxZm9o6ZLQl9z8/yu6a6YGZ3h/5/LzKzt80sye+apGbomB07x2yIveO2jtnRc8yOyGAcK7cwLacY+LlzrjswALg1Bva5zJ1Art9F1LFngQ+dcwGgDzGw/2aWDtwBZDnneuFdCDbK36qkJuiYHXPHbIi947aO2VFyzI7IYEwM3MK0POfceufcV6HpnXg/dOn+VlX7zKw98EPgZb9rqStm1gwYDPwPgHPugHNum79V1ZkEoJGZJQCN0Xi60ULH7Bg5ZkPsHbd1zI6uY3akBuOKbmEaEwccADPrDPQD5vpbSZ14BhgHlPpdSB3qAhQAr4Y+inzZzJL9Lqq2Oee+B54E1gDrge3Ouan+ViU1RMfs2DlmQ+wdt3XMjqJjdqQG4xO5/WlUMbMmwD+Bu5xzO/yupzaZ2SXAJufcPL9rqWMJwGnAi865fsBuIBb6ZKbgnUXMANoByWb2//ytSmqIjtkxcMyGmD1u65gdRcfsSA3GMXkLUzNLxDvAvuWce9fveurAIOAyM1uN99Hr+Wb2pr8l1Yl8IN85V3Z26R28g260uwBY5ZwrcM4VAe8CA32uSWqGjtmxccyG2Dxu65gdRcfsSA3GMXcLUzMzvP5Luc65p/2upy44537lnGvvnOuM9z3+2DkX8X+NHo9zbgOw1sy6hWYNBb71saS6sgYYYGaNQ//fhxIDF7DECB2zY0QsHrd1zI6uY3ZE3hK6jm9hWl8MAn4MLDSzBaF59zvnPvCxJqk9twNvhUJEHjDa53pqnXNurpm9A3yFd0X/fKLsVqOxSsdsHbNjgI7ZUXLM1i2hRURERESI3K4UIiIiIiI1SsFYRERERAQFYxERERERQMFYRERERARQMBYRERERARSMJYKYWYmZLQh71Nidhcyss5ktqqn3ExERHbcl8kTkOMYSs/Y65/r6XYSIiFSajtsSUXTGWCKema02sz+a2RehR9fQ/E5mNt3Mvgk9dwzNTzOzyWb2dehRdgvLeDP7q5ktNrOpZtbIt50SEYliOm5LfaVgLJGkUbmP5EaGte1wzvUHngeeCc17HnjDOdcbeAt4LjT/OWCmc64P3v3sy+7AlQm84JzrCWwDrqzl/RERiXY6bktE0Z3vJGKY2S7nXJMK5q8GznfO5ZlZIrDBOdfKzDYDbZ1zRaH5651zqWZWALR3zu0Pe4/OQNA5lxl6fR+Q6Jx7pPb3TEQkOum4LZFGZ4wlWrijTB9tmYrsD5suQX3wRURqk47bUu8oGEu0GBn2PCc0/RkwKjR9HfBpaHo6cDOAmcWbWbO6KlJERA7ScVvqHf1lJZGkkZktCHv9oXOubOifhmY2F++PvWtD8+4AXjGze4ECYHRo/p3ABDP7Gd4ZhpuB9bVevYhI7NFxWyKK+hhLxAv1Vctyzm32uxb5/9u1YxoAABiGYeGPehD29rBBTFE1gJ+7zSqvFAAAkMUYAAAqizEAAFTCGAAAKmEMAACVMAYAgEoYAwBAVQdKWHyI7JPLdAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss= 0.04779933765530586\n",
      "validation loss= 2.6234500408172607\n"
     ]
    }
   ],
   "source": [
    "plot_loss_curve(history2)\n",
    "print(\"train loss=\", history2.history['loss'][-1])\n",
    "print(\"validation loss=\", history2.history['val_loss'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: cnn01\\assets\n"
     ]
    }
   ],
   "source": [
    "model2.save('cnn01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv_layer1 (Conv2D)         (None, 298, 298, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 149, 149, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv_layer2 (Conv2D)         (None, 147, 147, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 73, 73, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341056)            0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 128)               43655296  \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 43,691,587\n",
      "Trainable params: 43,691,587\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = load_model(\"cnn01\")\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "141/141 [==============================] - 49s 349ms/step - loss: 2.6821 - accuracy: 0.5989\n",
      "accuracy: 59.89%\n"
     ]
    }
   ],
   "source": [
    "# 5. 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "scores = model2.evaluate(X_test, y_test)\n",
    "print(\"%s: %.2f%%\" %(model2.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Predict --\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1290d1cc93e8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 6. 모델 사용하기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-- Predict --\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_printoptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'float'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"{0:0.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1606\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1608\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1609\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1610\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[1;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m     \u001b[1;31m# Default to 32 for backwards compat.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m       \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msteps\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# 6. 모델 사용하기\n",
    "print(\"-- Predict --\")\n",
    "output = model2.predict(X_test, y_test)\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "print(test_img.class_indices)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
