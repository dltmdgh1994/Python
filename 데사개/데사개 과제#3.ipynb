{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymysql\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "StandardScaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 엑셀파일을 mysql의 테이블로 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('db_score_3_labels.xlsx')\n",
    "db = pymysql.connect(host='localhost',port=3306,user='root',passwd='iscream1023',db='mysql')\n",
    "cursor = db.cursor()\n",
    "query = \"\"\"CREATE TABLE IF NOT EXISTS db_score2(\n",
    "            sno int primary key,\n",
    "            homework float,\n",
    "            discussion int,\n",
    "            midterm float,\n",
    "            grade varchar(10))\"\"\"\n",
    "cursor.execute(query)\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IntegrityError",
     "evalue": "(1062, \"Duplicate entry '1' for key 'PRIMARY'\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bb2bdf55f35e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mquery\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, query, args)\u001b[0m\n\u001b[0;32m    161\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmogrify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_query\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymysql\\cursors.py\u001b[0m in \u001b[0;36m_query\u001b[1;34m(self, q)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_last_executed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m         \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrowcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mquery\u001b[1;34m(self, sql, unbuffered)\u001b[0m\n\u001b[0;32m    503\u001b[0m                 \u001b[0msql\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'surrogateescape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCOMMAND\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOM_QUERY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 505\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_query_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0munbuffered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    506\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_affected_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_query_result\u001b[1;34m(self, unbuffered)\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMySQLResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 724\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    725\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserver_status\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m             \u001b[0mfirst_packet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mfirst_packet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ok_packet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymysql\\connections.py\u001b[0m in \u001b[0;36m_read_packet\u001b[1;34m(self, packet_type)\u001b[0m\n\u001b[0;32m    674\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbuffered_active\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbuffered_active\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m             \u001b[0mpacket\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpacket\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymysql\\protocol.py\u001b[0m in \u001b[0;36mraise_for_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0merrno\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_uint16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"errno =\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrno\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m         \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_mysql_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymysql\\err.py\u001b[0m in \u001b[0;36mraise_mysql_exception\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merrorclass\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0merrorclass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInternalError\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0merrno\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1000\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mOperationalError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merrorclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIntegrityError\u001b[0m: (1062, \"Duplicate entry '1' for key 'PRIMARY'\")"
     ]
    }
   ],
   "source": [
    "query = \"INSERT INTO db_score2(sno,homework,discussion,midterm,grade) values \"\n",
    "for i in data.index:\n",
    "    s = \"({0},{1},{2},{3},{4}),\".format(data.iloc[i].sno, data.iloc[i].homework, data.iloc[i].discussion, data.iloc[i].midterm, \"\\'\"+data.iloc[i].grade+\"\\'\")\n",
    "    query += s\n",
    "\n",
    "cursor.execute(query[:-1])\n",
    "\n",
    "db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('db_score_3_labels.xlsx')\n",
    "x=data.drop('grade',axis=1).values\n",
    "y=np.array([])\n",
    "for d in data['grade'].values:\n",
    "    if d == 'B':\n",
    "        y=np.append(y,1)\n",
    "    else:\n",
    "        y=np.append(y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_performance_eval(test,predict):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for y,p in zip(test,predict):\n",
    "        if y == 1 and p == 1:\n",
    "            tp += 1\n",
    "        elif y == 1 and p == 0:\n",
    "            fn += 1\n",
    "        elif y == 0 and p == 1:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    \n",
    "    accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
    "    if tp != 0 or fp != 0:\n",
    "        precision = tp/(tp+fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "    if tp!= 0 or fn != 0:\n",
    "        recall = tp/(tp+fn)\n",
    "    else:\n",
    "        recall = 0\n",
    "    if precision != 0 or recall != 0:\n",
    "        f1 = 2*precision*recall/(precision+recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "        \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def print_performance(acc, pre, rec, f1):\n",
    "    print(\"average_accuracy : \", statistics.mean(acc))\n",
    "    print(\"average_precison : \", statistics.mean(pre))\n",
    "    print(\"average_recall : \", statistics.mean(rec))\n",
    "    print(\"average_f1_score : \", statistics.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.892857\n",
      "precison = 0.727273\n",
      "recall = 1.000000\n",
      "f1_score = 0.842105\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "model = SVC(random_state = 42)\n",
    "model.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy, precision, recall, f1 = classification_performance_eval(y_test,pred)\n",
    "\n",
    "print(\"accuracy = %f\" %accuracy)\n",
    "print(\"precison = %f\" %precision)\n",
    "print(\"recall = %f\" %recall)\n",
    "print(\"f1_score = %f\" %f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_accuracy :  0.935672514619883\n",
      "average_precison :  0.8568181818181818\n",
      "average_recall :  1.0\n",
      "average_f1_score :  0.918961038961039\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for t1,t2 in kf.split(x):\n",
    "    x_train,x_test = x[t1], x[t2]\n",
    "    y_train,y_test = y[t1], y[t2]\n",
    "    model.fit(x_train,y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    acc, pre, rec, f1 = classification_performance_eval(y_test,pred)\n",
    "    accuracy.append(acc)\n",
    "    precision.append(pre)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "\n",
    "print_performance(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.714286\n",
      "precison = 0.500000\n",
      "recall = 0.125000\n",
      "f1_score = 0.200000\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "\n",
    "StandardScaler.fit(x_train)\n",
    "train_data_StandardScale = StandardScaler.transform(x_train)\n",
    "StandardScaler.fit(x_test)\n",
    "test_data_StandardScale = StandardScaler.transform(x_test)\n",
    "model = LogisticRegression(random_state = 42)\n",
    "model.fit(train_data_StandardScale,y_train)\n",
    "pred = model.predict(test_data_StandardScale)\n",
    "accuracy, precision, recall, f1 = classification_performance_eval(y_test,pred)\n",
    "\n",
    "print(\"accuracy = %f\" %accuracy)\n",
    "print(\"precison = %f\" %precision)\n",
    "print(\"recall = %f\" %recall)\n",
    "print(\"f1_score = %f\" %f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_accuracy :  0.6181286549707602\n",
      "average_precison :  0.35\n",
      "average_recall :  0.12857142857142856\n",
      "average_f1_score :  0.15714285714285714\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for t1,t2 in kf.split(x):\n",
    "    x_train,x_test = x[t1], x[t2]\n",
    "    y_train,y_test = y[t1], y[t2]\n",
    "    \n",
    "    StandardScaler.fit(x_train)\n",
    "    train_data_StandardScale = StandardScaler.transform(x_train)\n",
    "    StandardScaler.fit(x_test)\n",
    "    test_data_StandardScale = StandardScaler.transform(x_test)\n",
    "    model = LogisticRegression(random_state = 42)\n",
    "    model.fit(train_data_StandardScale,y_train)\n",
    "    pred = model.predict(test_data_StandardScale)\n",
    "    acc, pre, rec, f1 = classification_performance_eval(y_test,pred)\n",
    "    accuracy.append(acc)\n",
    "    precision.append(pre)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "\n",
    "print_performance(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.964286\n",
      "precison = 1.000000\n",
      "recall = 0.875000\n",
      "f1_score = 0.933333\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "model = RandomForestClassifier(random_state = 42)\n",
    "model.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "accuracy, precision, recall, f1 = classification_performance_eval(y_test,pred)\n",
    "\n",
    "print(\"accuracy = %f\" %accuracy)\n",
    "print(\"precison = %f\" %precision)\n",
    "print(\"recall = %f\" %recall)\n",
    "print(\"f1_score = %f\" %f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average_accuracy :  0.967251461988304\n",
      "average_precison :  0.9818181818181818\n",
      "average_recall :  0.9314285714285714\n",
      "average_f1_score :  0.9528693528693528\n"
     ]
    }
   ],
   "source": [
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1_score = []\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for t1,t2 in kf.split(x):\n",
    "    x_train,x_test = x[t1], x[t2]\n",
    "    y_train,y_test = y[t1], y[t2]\n",
    "    model.fit(x_train,y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    acc, pre, rec, f1 = classification_performance_eval(y_test,pred)\n",
    "    accuracy.append(acc)\n",
    "    precision.append(pre)\n",
    "    recall.append(rec)\n",
    "    f1_score.append(f1)\n",
    "\n",
    "print_performance(accuracy, precision, recall, f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_performance_eval2(test,predict):\n",
    "    arr = []\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for y,p in zip(test,predict):\n",
    "        if y == 'A' and p == 'A':\n",
    "            tp += 1\n",
    "        elif y == 'A' and p != 'A':\n",
    "            fn += 1\n",
    "        elif y != 'A' and p == 'A':\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    \n",
    "    \n",
    "    if tp != 0 or fp != 0:\n",
    "        precision = tp/(tp+fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "    if tp != 0 or fn != 0:\n",
    "        recall = tp/(tp+fn)\n",
    "    else:\n",
    "        recall = 0\n",
    "    if precision != 0 or recall != 0:\n",
    "        f1 = 2*precision*recall/(precision+recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    arr.append([precision,recall,f1])\n",
    "    \n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for y,p in zip(test,predict):\n",
    "        if y == 'B' and p == 'B':\n",
    "            tp += 1\n",
    "        elif y == 'B' and p != 'B':\n",
    "            fn += 1\n",
    "        elif y != 'B' and p == 'B':\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    \n",
    "    if tp != 0 or fp != 0:\n",
    "        precision = tp/(tp+fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "    if tp != 0 or fn != 0:\n",
    "        recall = tp/(tp+fn)\n",
    "    else:\n",
    "        recall = 0\n",
    "    if precision != 0 or recall != 0:\n",
    "        f1 = 2*precision*recall/(precision+recall)\n",
    "    else:\n",
    "        f1 = 0\n",
    "    arr.append([precision,recall,f1])\n",
    "    \n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    \n",
    "    for y,p in zip(test,predict):\n",
    "        if y == 'C' and p == 'C':\n",
    "            tp += 1\n",
    "        elif y == 'C' and p != 'C':\n",
    "            fn += 1\n",
    "        elif y != 'C' and p == 'C':\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    \n",
    "    if tp != 0 or fp != 0:\n",
    "        precision = tp/(tp+fp)\n",
    "    else:\n",
    "        precision = 0\n",
    "    if tp != 0 or fn != 0:\n",
    "        recall = tp/(tp+fn)\n",
    "    else:\n",
    "        recall = 0 \n",
    "    if precision != 0 or recall != 0:\n",
    "        f1 = 2*precision*recall/(precision+recall)\n",
    "    else:\n",
    "        f1 = 0    \n",
    "    arr.append([precision,recall,f1])\n",
    "    \n",
    "    cnt, entire = 0, 0\n",
    "    for y,p in zip(test,predict):\n",
    "        entire += 1\n",
    "        if y == p:\n",
    "            cnt += 1\n",
    "    accuracy = cnt/entire\n",
    "    arr.append([accuracy,0,0])\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def print_multi_performance(arr):\n",
    "    print(\"A => precison = %f  recall = %f  f1_score = %f\" %(arr[0][0],arr[0][1],arr[0][2]))\n",
    "    print(\"B => precison = %f  recall = %f  f1_score = %f\" %(arr[1][0],arr[1][1],arr[1][2]))\n",
    "    print(\"C => precison = %f  recall = %f  f1_score = %f\" %(arr[2][0],arr[2][1],arr[2][2]))\n",
    "    print(\"accuracy = %f\" %(arr[3][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A => precison = 0.909091  recall = 1.000000  f1_score = 0.952381\n",
      "B => precison = 0.875000  recall = 0.875000  f1_score = 0.875000\n",
      "C => precison = 1.000000  recall = 0.900000  f1_score = 0.947368\n",
      "accuracy = 0.928571\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "model = SVC(random_state = 42)\n",
    "model.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "arr = classification_performance_eval2(y_test,pred)\n",
    "\n",
    "print_multi_performance(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance_mean\n",
      "A => precison = 0.742857  recall = 0.771429  f1_score = 0.751282\n",
      "B => precison = 0.960000  recall = 0.902857  f1_score = 0.926667\n",
      "C => precison = 0.971429  recall = 1.000000  f1_score = 0.984615\n",
      "accuracy = 0.956725\n"
     ]
    }
   ],
   "source": [
    "performance = np.array([[0,0,0],[0,0,0],[0,0,0],[0,0,0]])\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for t1,t2 in kf.split(x):\n",
    "    x_train,x_test = x[t1], x[t2]\n",
    "    y_train,y_test = y[t1], y[t2]\n",
    "    model.fit(x_train,y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    arr = classification_performance_eval2(y_test,pred)\n",
    "    arr = np.array(arr)\n",
    "    performance = performance + arr\n",
    "\n",
    "performance = performance/5\n",
    "performance = performance.tolist()\n",
    "print(\"performance_mean\")\n",
    "print_multi_performance(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistics Regression multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A => precison = 1.000000  recall = 0.800000  f1_score = 0.888889\n",
      "B => precison = 0.777778  recall = 0.875000  f1_score = 0.823529\n",
      "C => precison = 0.909091  recall = 1.000000  f1_score = 0.952381\n",
      "accuracy = 0.892857\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "\n",
    "StandardScaler.fit(x_train)\n",
    "train_data_StandardScale = StandardScaler.transform(x_train)\n",
    "StandardScaler.fit(x_test)\n",
    "test_data_StandardScale = StandardScaler.transform(x_test)\n",
    "model = LogisticRegression(random_state = 42)\n",
    "model.fit(train_data_StandardScale,y_train)\n",
    "pred = model.predict(test_data_StandardScale)\n",
    "arr = classification_performance_eval2(y_test,pred)\n",
    "\n",
    "print_multi_performance(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance_mean\n",
      "A => precison = 0.725000  recall = 0.596429  f1_score = 0.625641\n",
      "B => precison = 0.620000  recall = 0.640952  f1_score = 0.574545\n",
      "C => precison = 0.909524  recall = 0.916667  f1_score = 0.907093\n",
      "accuracy = 0.715205\n"
     ]
    }
   ],
   "source": [
    "performance = np.array([[0,0,0],[0,0,0],[0,0,0],[0,0,0]])\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for t1,t2 in kf.split(x):\n",
    "    x_train,x_test = x[t1], x[t2]\n",
    "    y_train,y_test = y[t1], y[t2]\n",
    "    \n",
    "    StandardScaler.fit(x_train)\n",
    "    train_data_StandardScale = StandardScaler.transform(x_train)\n",
    "    StandardScaler.fit(x_test)\n",
    "    test_data_StandardScale = StandardScaler.transform(x_test)\n",
    "    model = LogisticRegression(random_state = 42)\n",
    "    model.fit(train_data_StandardScale,y_train)\n",
    "    pred = model.predict(test_data_StandardScale)\n",
    "    arr = classification_performance_eval2(y_test,pred)\n",
    "    arr = np.array(arr)\n",
    "    performance = performance + arr\n",
    "\n",
    "performance = performance/5\n",
    "performance = performance.tolist()\n",
    "print(\"performance_mean\")\n",
    "print_multi_performance(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A => precison = 0.909091  recall = 1.000000  f1_score = 0.952381\n",
      "B => precison = 1.000000  recall = 0.875000  f1_score = 0.933333\n",
      "C => precison = 1.000000  recall = 1.000000  f1_score = 1.000000\n",
      "accuracy = 0.964286\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=42)\n",
    "model = RandomForestClassifier(random_state = 42)\n",
    "model.fit(x_train,y_train)\n",
    "pred = model.predict(x_test)\n",
    "arr = classification_performance_eval2(y_test,pred)\n",
    "\n",
    "print_multi_performance(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performance_mean\n",
      "A => precison = 0.766667  recall = 0.800000  f1_score = 0.781818\n",
      "B => precison = 0.981818  recall = 0.931429  f1_score = 0.952869\n",
      "C => precison = 0.971429  recall = 0.975000  f1_score = 0.971282\n",
      "accuracy = 0.967251\n"
     ]
    }
   ],
   "source": [
    "performance = np.array([[0,0,0],[0,0,0],[0,0,0],[0,0,0]])\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for t1,t2 in kf.split(x):\n",
    "    x_train,x_test = x[t1], x[t2]\n",
    "    y_train,y_test = y[t1], y[t2]\n",
    "    \n",
    "    model.fit(x_train,y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    arr = classification_performance_eval2(y_test,pred)\n",
    "    arr = np.array(arr)\n",
    "    performance = performance + arr\n",
    "\n",
    "performance = performance/5\n",
    "performance = performance.tolist()\n",
    "print(\"performance_mean\")\n",
    "print_multi_performance(performance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
