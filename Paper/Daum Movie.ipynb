{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다음 영화 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding=utf-8\n",
    "from urllib import parse\n",
    "from selenium import webdriver\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "hangul = re.compile('[^가-힣|^ |^0-9]+')\n",
    "driver = webdriver.Chrome('chromedriver')\n",
    "\n",
    "def dftoCsv(movie_df, num):\n",
    "    try: \n",
    "        movie_df.to_csv(('리뷰추가'+ str(num) +'.csv'), sep=',', na_rep='NaN', encoding='euc-kr',index = False) \n",
    "    except: \n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie = pd.read_csv(\"1c.csv\",sep=\",\",encoding = \"utf-8\")\n",
    "name = movie['Name'].tolist()\n",
    "num = movie['Num'].tolist()\n",
    "openDt = movie['OpenDt'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"배우 찾기\"\"\"\n",
    "at = []\n",
    "for n in num:\n",
    "    n = str(n)\n",
    "    try:\n",
    "        url = 'https://movie.daum.net/moviedb/main?movieId='+n\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html,\"html.parser\")\n",
    "        h = bs.findAll('dd',{'class':'type_ellipsis'})\n",
    "        actors = h[1].findAll('a',{'class','link_person #info #name'})\n",
    "        actor = []\n",
    "        for a in actors:\n",
    "            actor.append(a.text)\n",
    "        actor = \",\".join(actor)\n",
    "        at.append(actor)\n",
    "    except:\n",
    "        at.append('do not find movie')\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dic = {\"Actor\": at} \n",
    "movie_df = pd.DataFrame(movie_dic) \n",
    "\n",
    "dftoCsv(movie_df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "리뷰 찾기\n",
    "reviews = []\n",
    "movies = []\n",
    "score = []\n",
    "add = -1\n",
    "for n in num:\n",
    "    n = str(n)\n",
    "    add += 1\n",
    "    try:\n",
    "        url = 'https://movie.daum.net/moviedb/grade?movieId='+n+'&type=netizen&page=1'\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html,\"html.parser\")\n",
    "        h = bs.find('span',{'class','txt_menu'}).text\n",
    "        reviewNum = hangul.sub('',h)\n",
    "        limit = int(int(reviewNum)/10) + 2\n",
    "    except:\n",
    "        movies.append(name[add])\n",
    "        reviews.append('do not find movie')\n",
    "        continue\n",
    "    \n",
    "    for i in range(1,limit):\n",
    "        try:\n",
    "            page = str(i)\n",
    "            url = 'https://movie.daum.net/moviedb/grade?movieId='+n+'&type=netizen&page='+page\n",
    "            driver.get(url)\n",
    "            html = driver.page_source\n",
    "            bs = BeautifulSoup(html,\"html.parser\")\n",
    "            review = bs.find('ul',{'class':'list_review list_netizen'}).findAll('li')\n",
    "            for r in review:\n",
    "                t = r.find('span',{'class':'info_append'}).text\n",
    "                t = hangul.sub('',t)\n",
    "                t = t.strip()\n",
    "                t = int(t[:8])\n",
    "                if(t < openDt[add]):\n",
    "                    s = r.find('em',{'class':'emph_grade'}).text\n",
    "                    rw = r.find('p',{'class':'desc_review'}).text\n",
    "                    rw = hangul.sub('',rw)\n",
    "                    rw = rw.strip()\n",
    "                    if(rw != ''):\n",
    "                        movies.append(name[add])\n",
    "                        reviews.append(rw)\n",
    "                        score.append(s)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_dic = {\"Movie\": movies,\"Review\":reviews,\"Score\":score} \n",
    "movie_df = pd.DataFrame(movie_dic) \n",
    "\n",
    "dftoCsv(movie_df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "영화 번호 찾기\n",
    "movieName = pd.read_csv(\"1a.csv\",sep=\",\",encoding = \"utf-8\")\n",
    "Name = movieName['Name'].tolist()\n",
    "Num = []\n",
    "for n in Name:\n",
    "    try:\n",
    "        encode = parse.quote_plus(n)\n",
    "        url = 'https://search.daum.net/search?w=tot&q='+encode\n",
    "        driver.get(url)\n",
    "        html = driver.page_source\n",
    "        bs = BeautifulSoup(html,\"html.parser\")\n",
    "        h = bs.find('article',{'id':'mArticle'}).find('div',{'class':'wid_n'}).find('div',{'class':'info_movie'}).find('a')['href']\n",
    "        h = h[43:]\n",
    "        Num.append(h)\n",
    "    except:\n",
    "        Num.append('')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
