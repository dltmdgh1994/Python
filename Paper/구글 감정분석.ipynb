{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import language_v1\n",
    "from google.cloud.language_v1 import enums\n",
    "import pandas as pd\n",
    "\n",
    "client = language_v1.LanguageServiceClient()\n",
    "encoding_type = enums.EncodingType.UTF8\n",
    "language = \"ko\"\n",
    "type_ = enums.Document.Type.PLAIN_TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document sentiment score: 0.30000001192092896\n",
      "Document sentiment magnitude: 0.30000001192092896\n",
      "Sentence text: ^^^^^^^^^^^\n",
      "Sentence sentiment score: 0.30000001192092896\n",
      "Sentence sentiment magnitude: 0.30000001192092896\n",
      "Language of the text: ko\n"
     ]
    }
   ],
   "source": [
    "def sample_analyze_sentiment(text_content):\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # text_content = 'I am so happy and joyful.'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"ko\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
    "    # Get overall sentiment of the input document\n",
    "    print(u\"Document sentiment score: {}\".format(response.document_sentiment.score))\n",
    "    print(\n",
    "        u\"Document sentiment magnitude: {}\".format(\n",
    "            response.document_sentiment.magnitude\n",
    "        )\n",
    "    )\n",
    "    # Get sentiment for all sentences in the document\n",
    "    for sentence in response.sentences:\n",
    "        print(u\"Sentence text: {}\".format(sentence.text.content))\n",
    "        print(u\"Sentence sentiment score: {}\".format(sentence.sentiment.score))\n",
    "        print(u\"Sentence sentiment magnitude: {}\".format(sentence.sentiment.magnitude))\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n",
    "    \n",
    "sample_analyze_sentiment(\"^^^^^^^^^^^\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = pd.read_csv(\"review.csv\",sep=\",\",encoding = \"utf-8\")\n",
    "reviews = review['review'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "s.append(\".... \".join(reviews[:3000]))\n",
    "s.append(\".... \".join(reviews[3000:6000]))\n",
    "s.append(\".... \".join(reviews[6000:9000]))\n",
    "s.append(\".... \".join(reviews[9000:12000]))\n",
    "s.append(\".... \".join(reviews[12000:15000]))\n",
    "s.append(\".... \".join(reviews[15000:18000]))\n",
    "s.append(\".... \".join(reviews[18000:20000]))\n",
    "s.append(\".... \".join(reviews[20000:22000]))\n",
    "s.append(\".... \".join(reviews[22000:24000]))\n",
    "s.append(\".... \".join(reviews[24000:26000]))\n",
    "s.append(\".... \".join(reviews[26000:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_score = []\n",
    "s_s=[]\n",
    "for s1 in s:\n",
    "    document = {\"content\": s1, \"type\": type_, \"language\": language}\n",
    "    response = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
    "\n",
    "    for sentence in response.sentences:\n",
    "        s_s.append(sentence.text.content)\n",
    "        s_score.append(sentence.sentiment.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = []\n",
    "for s2 in s_s:\n",
    "    if '....' in s2:\n",
    "        sen.append(s2[:-4])\n",
    "    else:\n",
    "        sen.append(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "97\n",
      "412\n",
      "601\n",
      "777\n",
      "1009\n",
      "1067\n",
      "1133\n",
      "1146\n",
      "1157\n",
      "1270\n",
      "1402\n",
      "1474\n",
      "1501\n",
      "1598\n",
      "1707\n",
      "1711\n",
      "2253\n",
      "2367\n",
      "2375\n",
      "2755\n",
      "2816\n",
      "2981\n",
      "3089\n",
      "3827\n",
      "4056\n",
      "4356\n",
      "4589\n",
      "4615\n",
      "4928\n",
      "5156\n",
      "5463\n",
      "5514\n",
      "5807\n",
      "5872\n",
      "6158\n",
      "6187\n",
      "6308\n",
      "6406\n",
      "6649\n",
      "6709\n",
      "7500\n",
      "7726\n",
      "8490\n",
      "9328\n",
      "9623\n",
      "10069\n",
      "10619\n",
      "10752\n",
      "10803\n",
      "11673\n",
      "11696\n",
      "12031\n",
      "12083\n",
      "12266\n",
      "12717\n",
      "13625\n",
      "14433\n",
      "14968\n",
      "15087\n",
      "15127\n",
      "15795\n",
      "15891\n",
      "16124\n",
      "16153\n",
      "16581\n",
      "16632\n",
      "16952\n",
      "17343\n",
      "17589\n",
      "17600\n",
      "18017\n",
      "18070\n",
      "18357\n",
      "18373\n",
      "19030\n",
      "19037\n",
      "19268\n",
      "20642\n",
      "20874\n",
      "20935\n",
      "21029\n",
      "21348\n",
      "21467\n",
      "21474\n",
      "21664\n",
      "21994\n",
      "22094\n",
      "22172\n",
      "22409\n",
      "22664\n",
      "22787\n",
      "22832\n",
      "23010\n",
      "23990\n",
      "24102\n",
      "24343\n",
      "24473\n",
      "24528\n",
      "24559\n",
      "24771\n",
      "24785\n",
      "24846\n",
      "24863\n",
      "24868\n",
      "24964\n",
      "24965\n",
      "24974\n",
      "25140\n",
      "25733\n",
      "25817\n",
      "26026\n",
      "26773\n"
     ]
    }
   ],
   "source": [
    "sen2 = []\n",
    "score2 = []\n",
    "num = 0\n",
    "for s3 in sen:\n",
    "    a = s3.split('.... ')\n",
    "    if len(a) > 1:\n",
    "        for a1 in a:\n",
    "            sen2.append(a1)\n",
    "            document = {\"content\": a1, \"type\": type_, \"language\": language}\n",
    "            response = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
    "            score2.append(response.document_sentiment.score)  \n",
    "        print(num)\n",
    "    else:\n",
    "        sen2.append(a[0])\n",
    "        score2.append(s_score[num])\n",
    "    num += 1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dftoCsv(movie_df, num):\n",
    "    try: \n",
    "        movie_df.to_csv(('r'+ str(num) +'.csv'), sep=',', na_rep='NaN', encoding='euc-kr',index = False) \n",
    "    except: \n",
    "        print(\"Error\")\n",
    "        \n",
    "movie_dic = {\"review\": sen2 ,\"구글 감정점수\" : score2 } \n",
    "movie_df = pd.DataFrame(movie_dic) \n",
    "\n",
    "dftoCsv(movie_df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document sentiment score: 0.8999999761581421\n",
      "Document sentiment magnitude: 0.8999999761581421\n",
      "Sentence text: 기대되네요\n",
      "Sentence sentiment score: 0.8999999761581421\n",
      "Sentence sentiment magnitude: 0.8999999761581421\n",
      "Language of the text: ko\n"
     ]
    }
   ],
   "source": [
    "def sample_analyze_sentiment(text_content):\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # text_content = 'I am so happy and joyful.'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"ko\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
    "    # Get overall sentiment of the input document\n",
    "    print(u\"Document sentiment score: {}\".format(response.document_sentiment.score))\n",
    "    print(\n",
    "        u\"Document sentiment magnitude: {}\".format(\n",
    "            response.document_sentiment.magnitude\n",
    "        )\n",
    "    )\n",
    "    # Get sentiment for all sentences in the document\n",
    "    for sentence in response.sentences:\n",
    "        print(u\"Sentence text: {}\".format(sentence.text.content))\n",
    "        print(u\"Sentence sentiment score: {}\".format(sentence.sentiment.score))\n",
    "        print(u\"Sentence sentiment magnitude: {}\".format(sentence.sentiment.magnitude))\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n",
    "    \n",
    "sample_analyze_sentiment(\"기대되네요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def sample_analyze_sentiment(text_content):\n",
    "\n",
    "    client = language_v1.LanguageServiceClient()\n",
    "\n",
    "    # text_content = 'I am so happy and joyful.'\n",
    "\n",
    "    # Available types: PLAIN_TEXT, HTML\n",
    "    type_ = enums.Document.Type.PLAIN_TEXT\n",
    "\n",
    "    # Optional. If not specified, the language is automatically detected.\n",
    "    # For list of supported languages:\n",
    "    # https://cloud.google.com/natural-language/docs/languages\n",
    "    language = \"ko\"\n",
    "    document = {\"content\": text_content, \"type\": type_, \"language\": language}\n",
    "\n",
    "    # Available values: NONE, UTF8, UTF16, UTF32\n",
    "    encoding_type = enums.EncodingType.UTF8\n",
    "\n",
    "    response = client.analyze_sentiment(document, encoding_type=encoding_type)\n",
    "    # Get overall sentiment of the input document\n",
    "    print(u\"Document sentiment score: {}\".format(response.document_sentiment.score))\n",
    "    print(\n",
    "        u\"Document sentiment magnitude: {}\".format(\n",
    "            response.document_sentiment.magnitude\n",
    "        )\n",
    "    )\n",
    "    # Get sentiment for all sentences in the document\n",
    "    for sentence in response.sentences:\n",
    "        print(u\"Sentence text: {}\".format(sentence.text.content))\n",
    "        print(u\"Sentence sentiment score: {}\".format(sentence.sentiment.score))\n",
    "        print(u\"Sentence sentiment magnitude: {}\".format(sentence.sentiment.magnitude))\n",
    "\n",
    "    # Get the language of the text, which will be the same as\n",
    "    # the language specified in the request or, if not specified,\n",
    "    # the automatically-detected language.\n",
    "    print(u\"Language of the text: {}\".format(response.language))\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
